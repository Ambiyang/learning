import pandas
titanic = pandas.read_csv("titanic_train.csv")
titanic.head(5)
#print(titanic.describe())


titanic["Age"] = titanic["Age"].fillna(titanic["Age"].median())
print titanic.describe()


print titanic.unique()

titanic.loc[titanic["Sex"] == "male", "Sex"] = 0
titanic.loc[titanic["Sex"] == "female", "Sex"] = 1


print titanic["Embarked"].unique()
titanic["Embarked"] = titanic["Embarked"].fillna('S')
titanic.loc[titanic["Embarked"] == "S", "Embarked"] = 0
titanic.loc[titanic["Embarked"] == "C", "Embarked"] = 1
titanic.loc[titanic["Embarked"] == "Q", "Embarked"] = 2


from sklearn.linear_model import LinearRegression
from sklearn.cross_validation import KFold

predictors =["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked"]

alg  = LinearRegression()

kf = KFold(titanic.shape[0], n_folds = 3, random_state = 1)

predictions = []
for train,test in kf:
	train_predictors =(titanic[predictors].iloc[train,:])
	train_target = titanic["Survived"].iloc[train]
	alg.fit(train_predictors,train_target)
	train_predictions = alg.predict(titanic[predictors].iloc[test,:])
	train_predictors.append(train_predictions)

import numpy as np

predictions = np.concatenate(predictions, axis = 0)

predictions[predictions > .5] = 1
predictions[predictions <= .5] = 0
accuracy = sum(predictions[predictions == titanaic["Survived"]]) / len(predictions)
print accuracy


from sklearn import cross_validation
from sklearn.linear_model import LogisticRegression

alg  = LogisticRegression(random_state = 1)

scores = cross_validation.cross_val_score(alg,titanic[predictors],titanaic["Survived"],cv=3)

print(scores.mean())


titanic_test = pandas.read_csv("test.csv")
titanic_test["Age"] = titanic_test["Age"].fillna(titanic["Age"].median())
titanic_test["Fare"] = titanic_test["fare"].fillna(titanic_test["fare"].median())
titanic_test.loc[titanic_test["Sex"] == "male", "Sex"] = 0
titanic_test.loc[titanic_test["Sex"] == "female", "Sex"] = 1
titanic_test["Embarked"] = titanic_test["Embarked"].fillna("S")
titanic_test.loc[titanic_test["Embarked"] == "S", "Embarked"] = 0
titanic_test.loc[titanic_test["Embarked"] == "C", "Embarked"] = 1
titanic_test.loc[titanic_test["Embarked"] == "Q", "Embarked"] = 2


from sklearn import cross_validation
from sklearn.ensemble import RandomForestClassifier

predictors =["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked"]

alg = RandomForestClassifier(random_state = 1,n_estimators=20,min_samples_split=2,min_samples_leaf=1)

kf = cross_validation.KFold(titanic.shape[0], n_folds = 3, random_state = 1)

scores = cross_validation.cross_val_score(alg,titanic[predictors],titanaic["Survived"],cv=kf)

print(scores.mean())


titanic["FamilySize"] = titanic["SibSp"] + titanic["Parch"]
titanic["NameLength"] = titanic["Name"].apply(lambda x:len(x))


import re

def get_title(name):
	title_search = re.search(' ([A-Za-z]+)\.',name)
	if title_search:
		return title_search.group(1)
	return ""

titles = titanic["Name"].apply(get_title)
print(pandas.value_counts(titles))

title_mapping = {"Mr":1, "Miss":2 ,"Mrs":3, "Master":4, "Dr":5, "Rev":6,"Major":7,"Col":7,"M1le":8,"Countess":8,"Ms":9,"Lady":10,"Jonkheer":11,"Don":12,"Mme":13,"Capt":14,"Sir":15}
for k,v in title_mapping.items():
	title[titles == k] = v

print(pandas.value_counts(titles))

titanic["Title"] = titles


import numpy as np
from sklearn.feature_selection import SelectKBest, f_classif
import matplotlib.pyplot as plt
predictions =["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked","FamilySize","Title","NameLenth"]

selector = SelectKBest(f_classif, k=5)
selector.fit(titanic[predictors],titanic["Survived"])

scores = -np.log10(selectors.pvalues_)

plt.bar(range(len(predictors)),scores)
plt.xticks(range(len(predictors)),predictors,rotation="vertical")
plt.show()

predictors = ["Pclass","Sex","Fare","Title"]

alg = RandomForestClassifier(random_state = 1,n_estimators=50,min_samples_split=8,min_samples_leaf=4)


from sklearn.ensemble import GradientBoostClassifier
import numpy as np

algorithms = [
[GradientBoostClassifier(random_state=1,n_estimators=25,max_depth=3),["Pclass","Sex","Fare","Title"]],
[LogisticRegression(random_state = 1),["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked"]]
]

kf = KFold(titanic.shape[0], n_folds = 3, random_state = 1)

predictions = []
for train,test in kf:
	train_test_predictors =[]
	train_target = titanic["Survived"].iloc[train]

	for alg,predictions in algorithms:
		alg.fit(titanic[predictors].iloc[train,:],train_target)
		test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]
		train_test_predictors.append(test_predictions)

	test_predictions[test_predictions > .5] = 1
	test_predictions[test_predictions <= .5] = 0
	predictions.append(test_predictions)


predictions = np.concatenate(predicionts, axis=0)

accuracy = sum(predictions[predictions == titanaic["Survived"]]) / len(predictions)
print accuracy


titles = titanic["Name"].apply(get_title)
print(pandas.value_counts(titles))

title_mapping = {"Mr":1, "Miss":2 ,"Mrs":3, "Master":4, "Dr":5, "Rev":6,"Major":7,"Col":7,"M1le":8,"Countess":8,"Ms":9,"Lady":10,"Jonkheer":11,"Don":12,"Mme":13,"Capt":14,"Sir":15}
for k,v in title_mapping.items():
	title[titles == k] = v
titanic["Title"] = titles

print(pandas.value_counts(titanic_test["Title"]))

titanic_test["FamilySize"] = titanic_test["SibSp"] + titanic_test["Parch"]


predictors = ["Pclass","Sex","Fare","Title"]

algorithms = [
[GradientBoostClassifier(random_state=1,n_estimators=25,max_depth=3),predictors],
[LogisticRegression(random_state = 1),["Pclass","Sex","Age","SibSp","Parch","Fare","Embarked"]]
]

full_predicionts = []
for alg,predictions in algorithms:
		alg.fit(titanic[predictors],titanic["Survived"])
		predictors = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]
		full_predicionts.append(predictions)

predictions = (full_predictions[0] * 3 + full_predictions[1] / 4)
predictions